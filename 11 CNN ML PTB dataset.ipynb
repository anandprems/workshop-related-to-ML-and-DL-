{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RtHc6pyKv9Uu"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "szRYFwrnv9Ux"
   },
   "outputs": [],
   "source": [
    "#importing datasets\n",
    "normal = pd.read_csv('ptbdb_normal.csv')\n",
    "abnormal = pd.read_csv('ptbdb_abnormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "ZTxNB11-v9Uy",
    "outputId": "2f0e5482-a446-498f-a1e4-c15f53886bda",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.000000000000000000e+00</th>\n",
       "      <th>9.003241658210754395e-01</th>\n",
       "      <th>3.585899472236633301e-01</th>\n",
       "      <th>5.145867168903350830e-02</th>\n",
       "      <th>4.659643396735191345e-02</th>\n",
       "      <th>1.268233358860015869e-01</th>\n",
       "      <th>1.333063244819641113e-01</th>\n",
       "      <th>1.191247999668121338e-01</th>\n",
       "      <th>1.106158867478370667e-01</th>\n",
       "      <th>1.130470037460327148e-01</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000000000000000000e+00.56</th>\n",
       "      <th>0.000000000000000000e+00.57</th>\n",
       "      <th>0.000000000000000000e+00.58</th>\n",
       "      <th>0.000000000000000000e+00.59</th>\n",
       "      <th>0.000000000000000000e+00.60</th>\n",
       "      <th>0.000000000000000000e+00.61</th>\n",
       "      <th>0.000000000000000000e+00.62</th>\n",
       "      <th>0.000000000000000000e+00.63</th>\n",
       "      <th>0.000000000000000000e+00.64</th>\n",
       "      <th>0.000000000000000000e+00.65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.375387</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171923</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.293754</td>\n",
       "      <td>0.325912</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.791482</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.074957</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478893</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.081289</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.048774</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.041643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867238</td>\n",
       "      <td>0.201360</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.141336</td>\n",
       "      <td>0.120934</td>\n",
       "      <td>0.108516</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948983</td>\n",
       "      <td>0.505265</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.059550</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.111293</td>\n",
       "      <td>0.116558</td>\n",
       "      <td>0.118192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.000000000000000000e+00  9.003241658210754395e-01  \\\n",
       "0                  1.000000                  0.794681   \n",
       "1                  0.909029                  0.791482   \n",
       "2                  1.000000                  0.478893   \n",
       "3                  1.000000                  0.867238   \n",
       "4                  0.948983                  0.505265   \n",
       "\n",
       "   3.585899472236633301e-01  5.145867168903350830e-02  \\\n",
       "0                  0.375387                  0.116883   \n",
       "1                  0.423169                  0.186712   \n",
       "2                  0.056760                  0.064176   \n",
       "3                  0.201360                  0.099349   \n",
       "4                  0.004176                  0.022513   \n",
       "\n",
       "   4.659643396735191345e-02  1.268233358860015869e-01  \\\n",
       "0                  0.000000                  0.171923   \n",
       "1                  0.000000                  0.007836   \n",
       "2                  0.081289                  0.072732   \n",
       "3                  0.141336                  0.120934   \n",
       "4                  0.059550                  0.107298   \n",
       "\n",
       "   1.333063244819641113e-01  1.191247999668121338e-01  \\\n",
       "0                  0.283859                  0.293754   \n",
       "1                  0.063032                  0.077002   \n",
       "2                  0.055619                  0.048774   \n",
       "3                  0.108516                  0.096393   \n",
       "4                  0.110385                  0.111293   \n",
       "\n",
       "   1.106158867478370667e-01  1.130470037460327148e-01  ...  \\\n",
       "0                  0.325912                  0.345083  ...   \n",
       "1                  0.074957                  0.077342  ...   \n",
       "2                  0.054478                  0.041643  ...   \n",
       "3                  0.093436                  0.100828  ...   \n",
       "4                  0.116558                  0.118192  ...   \n",
       "\n",
       "   0.000000000000000000e+00.56  0.000000000000000000e+00.57  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.58  0.000000000000000000e+00.59  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.60  0.000000000000000000e+00.61  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.62  0.000000000000000000e+00.63  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   0.000000000000000000e+00.64  0.000000000000000000e+00.65  \n",
       "0                          0.0                          0.0  \n",
       "1                          0.0                          0.0  \n",
       "2                          0.0                          0.0  \n",
       "3                          0.0                          0.0  \n",
       "4                          0.0                          0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing normal dataset\n",
    "normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "l2sfUt2qv9Uy",
    "outputId": "794db13d-c0e2-4ace-dc73-83d4120ba5df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9.322328567504882812e-01</th>\n",
       "      <th>8.696785569190979004e-01</th>\n",
       "      <th>8.861859440803527832e-01</th>\n",
       "      <th>9.296264052391052246e-01</th>\n",
       "      <th>9.087749719619750977e-01</th>\n",
       "      <th>9.339704513549804688e-01</th>\n",
       "      <th>8.010425567626953125e-01</th>\n",
       "      <th>7.497828006744384766e-01</th>\n",
       "      <th>6.872285008430480957e-01</th>\n",
       "      <th>6.350998878479003906e-01</th>\n",
       "      <th>...</th>\n",
       "      <th>0.000000000000000000e+00.117</th>\n",
       "      <th>0.000000000000000000e+00.118</th>\n",
       "      <th>0.000000000000000000e+00.119</th>\n",
       "      <th>0.000000000000000000e+00.120</th>\n",
       "      <th>0.000000000000000000e+00.121</th>\n",
       "      <th>0.000000000000000000e+00.122</th>\n",
       "      <th>0.000000000000000000e+00.123</th>\n",
       "      <th>0.000000000000000000e+00.124</th>\n",
       "      <th>0.000000000000000000e+00.125</th>\n",
       "      <th>1.000000000000000000e+00.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606941</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.223567</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>0.253430</td>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.153349</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.791859</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.667435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.899261</td>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.328096</td>\n",
       "      <td>0.367837</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935618</td>\n",
       "      <td>0.801661</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>0.480789</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.319834</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925265</td>\n",
       "      <td>0.433352</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>0.136643</td>\n",
       "      <td>0.182934</td>\n",
       "      <td>0.182934</td>\n",
       "      <td>0.182376</td>\n",
       "      <td>0.196877</td>\n",
       "      <td>0.203569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   9.322328567504882812e-01  8.696785569190979004e-01  \\\n",
       "0                  1.000000                  0.606941   \n",
       "1                  1.000000                  0.951613   \n",
       "2                  0.977819                  0.899261   \n",
       "3                  0.935618                  0.801661   \n",
       "4                  0.925265                  0.433352   \n",
       "\n",
       "   8.861859440803527832e-01  9.296264052391052246e-01  \\\n",
       "0                  0.384181                  0.254237   \n",
       "1                  0.923963                  0.853303   \n",
       "2                  0.230129                  0.032348   \n",
       "3                  0.805815                  1.000000   \n",
       "4                  0.073620                  0.079197   \n",
       "\n",
       "   9.087749719619750977e-01  9.339704513549804688e-01  \\\n",
       "0                  0.223567                  0.276836   \n",
       "1                  0.791859                  0.734255   \n",
       "2                  0.142329                  0.223660   \n",
       "3                  0.722741                  0.480789   \n",
       "4                  0.136643                  0.182934   \n",
       "\n",
       "   8.010425567626953125e-01  7.497828006744384766e-01  \\\n",
       "0                  0.253430                  0.184826   \n",
       "1                  0.672043                  0.685100   \n",
       "2                  0.328096                  0.367837   \n",
       "3                  0.454829                  0.319834   \n",
       "4                  0.182934                  0.182376   \n",
       "\n",
       "   6.872285008430480957e-01  6.350998878479003906e-01  ...  \\\n",
       "0                  0.153349                  0.121872  ...   \n",
       "1                  0.670507                  0.667435  ...   \n",
       "2                  0.381701                  0.389094  ...   \n",
       "3                  0.266874                  0.308411  ...   \n",
       "4                  0.196877                  0.203569  ...   \n",
       "\n",
       "   0.000000000000000000e+00.117  0.000000000000000000e+00.118  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.119  0.000000000000000000e+00.120  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.121  0.000000000000000000e+00.122  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.123  0.000000000000000000e+00.124  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   0.000000000000000000e+00.125  1.000000000000000000e+00.1  \n",
       "0                           0.0                         1.0  \n",
       "1                           0.0                         1.0  \n",
       "2                           0.0                         1.0  \n",
       "3                           0.0                         1.0  \n",
       "4                           0.0                         1.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing abnormal dataset\n",
    "abnormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kphuJzwev9Uz",
    "outputId": "84cc82a7-ce8e-4134-b8b7-499b95b9aa51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4045, 188)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimenion for normal\n",
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpMtI2Fiv9Uz",
    "outputId": "b46424fc-750c-44cb-e7d8-b0a793da7a34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10505, 188)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimension for abnormal\n",
    "abnormal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yIvhex_Uv9U0"
   },
   "outputs": [],
   "source": [
    "#changing the random column names to sequential - normal\n",
    "#as we have some numbers name as columns we need to change that to numbers as\n",
    "for normals in normal:\n",
    "    normal.columns = list(range(len(normal.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "GoHZnvB5v9U0",
    "outputId": "b19f023e-5024-483d-c733-44d3a29d5f44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.375387</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171923</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.293754</td>\n",
       "      <td>0.325912</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909029</td>\n",
       "      <td>0.791482</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.077002</td>\n",
       "      <td>0.074957</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478893</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.064176</td>\n",
       "      <td>0.081289</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.048774</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.041643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867238</td>\n",
       "      <td>0.201360</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.141336</td>\n",
       "      <td>0.120934</td>\n",
       "      <td>0.108516</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948983</td>\n",
       "      <td>0.505265</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.059550</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.111293</td>\n",
       "      <td>0.116558</td>\n",
       "      <td>0.118192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.794681  0.375387  0.116883  0.000000  0.171923  0.283859   \n",
       "1  0.909029  0.791482  0.423169  0.186712  0.000000  0.007836  0.063032   \n",
       "2  1.000000  0.478893  0.056760  0.064176  0.081289  0.072732  0.055619   \n",
       "3  1.000000  0.867238  0.201360  0.099349  0.141336  0.120934  0.108516   \n",
       "4  0.948983  0.505265  0.004176  0.022513  0.059550  0.107298  0.110385   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.293754  0.325912  0.345083  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.077002  0.074957  0.077342  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.048774  0.054478  0.041643  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.096393  0.093436  0.100828  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.111293  0.116558  0.118192  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing edited columns for normal data\n",
    "normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1cUsWMpJv9U1"
   },
   "outputs": [],
   "source": [
    "#changing the random column names to sequential - abnormal\n",
    "#as we have some numbers name as columns we need to change that to numbers as\n",
    "for abnormals in abnormal:\n",
    "    abnormal.columns = list(range(len(abnormal.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "EmKzFz9Xv9U1",
    "outputId": "20c0b82e-d852-46e5-97cf-d2e85081e4df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606941</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.223567</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>0.253430</td>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.153349</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.791859</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.667435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.899261</td>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.328096</td>\n",
       "      <td>0.367837</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935618</td>\n",
       "      <td>0.801661</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>0.480789</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.319834</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925265</td>\n",
       "      <td>0.433352</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>0.136643</td>\n",
       "      <td>0.182934</td>\n",
       "      <td>0.182934</td>\n",
       "      <td>0.182376</td>\n",
       "      <td>0.196877</td>\n",
       "      <td>0.203569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.606941  0.384181  0.254237  0.223567  0.276836  0.253430   \n",
       "1  1.000000  0.951613  0.923963  0.853303  0.791859  0.734255  0.672043   \n",
       "2  0.977819  0.899261  0.230129  0.032348  0.142329  0.223660  0.328096   \n",
       "3  0.935618  0.801661  0.805815  1.000000  0.722741  0.480789  0.454829   \n",
       "4  0.925265  0.433352  0.073620  0.079197  0.136643  0.182934  0.182934   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.184826  0.153349  0.121872  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.685100  0.670507  0.667435  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.367837  0.381701  0.389094  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.319834  0.266874  0.308411  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.182376  0.196877  0.203569  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  1.0  \n",
       "1  0.0  1.0  \n",
       "2  0.0  1.0  \n",
       "3  0.0  1.0  \n",
       "4  0.0  1.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing edited columns for abnormal data\n",
    "abnormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ikS2enNjv9U2"
   },
   "outputs": [],
   "source": [
    "#combining two data into one\n",
    "#suffling the dataset and dropping the index\n",
    "#As when concatenating we all have arranged 0 and 1 class in order manner\n",
    "dataset = pd.concat([normal, abnormal], axis=0).sample(frac=1.0, random_state =0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "kGVvA6RRv9U2",
    "outputId": "1abbf628-8de4-483e-da44-671105860bd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487164</td>\n",
       "      <td>0.368582</td>\n",
       "      <td>0.424205</td>\n",
       "      <td>0.346577</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>0.287897</td>\n",
       "      <td>0.295232</td>\n",
       "      <td>0.333741</td>\n",
       "      <td>0.306846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.981252</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.410949</td>\n",
       "      <td>0.155980</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.064867</td>\n",
       "      <td>0.130484</td>\n",
       "      <td>0.123360</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.960156</td>\n",
       "      <td>0.596484</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.286719</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.108984</td>\n",
       "      <td>0.040234</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.030469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526476</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.384662</td>\n",
       "      <td>0.421181</td>\n",
       "      <td>0.335971</td>\n",
       "      <td>0.231284</td>\n",
       "      <td>0.276324</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.237371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.957125</td>\n",
       "      <td>0.695460</td>\n",
       "      <td>0.343001</td>\n",
       "      <td>0.159521</td>\n",
       "      <td>0.085750</td>\n",
       "      <td>0.075662</td>\n",
       "      <td>0.108449</td>\n",
       "      <td>0.089533</td>\n",
       "      <td>0.108449</td>\n",
       "      <td>0.105296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.487164  0.368582  0.424205  0.346577  0.328851  0.287897   \n",
       "1  0.960630  0.981252  0.764154  0.410949  0.155980  0.009749  0.064867   \n",
       "2  0.960156  0.596484  0.528906  0.286719  0.113281  0.108984  0.040234   \n",
       "3  1.000000  0.526476  0.387097  0.384662  0.421181  0.335971  0.231284   \n",
       "4  0.957125  0.695460  0.343001  0.159521  0.085750  0.075662  0.108449   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.295232  0.333741  0.306846  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.130484  0.123360  0.126359  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.021484  0.030469  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.276324  0.211808  0.237371  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.089533  0.108449  0.105296  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  1.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  1.0  \n",
       "3  0.0  1.0  \n",
       "4  0.0  1.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing combined dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPzLjNQDv9U2",
    "outputId": "82220884-2798-451a-f78d-8ce263e44bfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14550, 188)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "GoJt_1A0v9U3",
    "outputId": "0418c8fc-8489-4d57-bb9c-bd0e013d8445"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.000000</td>\n",
       "      <td>14550.0</td>\n",
       "      <td>14550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.976638</td>\n",
       "      <td>0.721640</td>\n",
       "      <td>0.403068</td>\n",
       "      <td>0.242859</td>\n",
       "      <td>0.207181</td>\n",
       "      <td>0.216410</td>\n",
       "      <td>0.221718</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>0.227325</td>\n",
       "      <td>0.229684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.195694</td>\n",
       "      <td>0.249779</td>\n",
       "      <td>0.249466</td>\n",
       "      <td>0.218030</td>\n",
       "      <td>0.192331</td>\n",
       "      <td>0.180687</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.176642</td>\n",
       "      <td>0.176557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.014034</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.624227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.959381</td>\n",
       "      <td>0.584500</td>\n",
       "      <td>0.212294</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.061899</td>\n",
       "      <td>0.090473</td>\n",
       "      <td>0.096495</td>\n",
       "      <td>0.097092</td>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.097127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740115</td>\n",
       "      <td>0.371911</td>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.136082</td>\n",
       "      <td>0.159451</td>\n",
       "      <td>0.167479</td>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.177380</td>\n",
       "      <td>0.180337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881478</td>\n",
       "      <td>0.557741</td>\n",
       "      <td>0.336155</td>\n",
       "      <td>0.264083</td>\n",
       "      <td>0.264610</td>\n",
       "      <td>0.286449</td>\n",
       "      <td>0.302235</td>\n",
       "      <td>0.311657</td>\n",
       "      <td>0.325235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985523</td>\n",
       "      <td>0.993213</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>0.773743</td>\n",
       "      <td>0.789804</td>\n",
       "      <td>0.628177</td>\n",
       "      <td>0.602033</td>\n",
       "      <td>0.644880</td>\n",
       "      <td>0.371502</td>\n",
       "      <td>0.376668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  14550.000000  14550.000000  14550.000000  14550.000000  14550.000000   \n",
       "mean       0.976638      0.721640      0.403068      0.242859      0.207181   \n",
       "std        0.034532      0.195694      0.249779      0.249466      0.218030   \n",
       "min        0.624227      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.959381      0.584500      0.212294      0.052278      0.061899   \n",
       "50%        1.000000      0.740115      0.371911      0.168148      0.136082   \n",
       "75%        1.000000      0.881478      0.557741      0.336155      0.264083   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  14550.000000  14550.000000  14550.000000  14550.000000  14550.000000   \n",
       "mean       0.216410      0.221718      0.224457      0.227325      0.229684   \n",
       "std        0.192331      0.180687      0.176900      0.176642      0.176557   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.090473      0.096495      0.097092      0.097225      0.097127   \n",
       "50%        0.159451      0.167479      0.171541      0.177380      0.180337   \n",
       "75%        0.264610      0.286449      0.302235      0.311657      0.325235   \n",
       "max        1.000000      1.000000      0.985523      0.993213      0.997738   \n",
       "\n",
       "       ...           178           179           180           181  \\\n",
       "count  ...  14550.000000  14550.000000  14550.000000  14550.000000   \n",
       "mean   ...      0.001190      0.001133      0.000900      0.000739   \n",
       "std    ...      0.021363      0.021014      0.017317      0.014641   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.791899      0.773743      0.789804      0.628177   \n",
       "\n",
       "                182           183           184           185      186  \\\n",
       "count  14550.000000  14550.000000  14550.000000  14550.000000  14550.0   \n",
       "mean       0.000661      0.000475      0.000177      0.000185      0.0   \n",
       "std        0.014034      0.012290      0.006545      0.006836      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.0   \n",
       "max        0.602033      0.644880      0.371502      0.376668      0.0   \n",
       "\n",
       "                187  \n",
       "count  14550.000000  \n",
       "mean       0.721993  \n",
       "std        0.448032  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic info of statistics\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rBU3nNbv9U3",
    "outputId": "35f35b63-8c2d-4e0d-f35b-157557a4d5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14550 entries, 0 to 14549\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 20.9 MB\n"
     ]
    }
   ],
   "source": [
    "#basic information of dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-9gTg6Nv9U3",
    "outputId": "64a155e4-ba8b-4157-faba-90e771c30306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6905\n",
       "1      13303\n",
       "2      14020\n",
       "3      12749\n",
       "4      13172\n",
       "       ...  \n",
       "183       33\n",
       "184       15\n",
       "185       15\n",
       "186        1\n",
       "187        2\n",
       "Length: 188, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the uniqueness in dataset\n",
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUCElKiUv9U3",
    "outputId": "fa278373-d664-412a-a12c-785eb2f13cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing data or NaN in the dataset: False\n"
     ]
    }
   ],
   "source": [
    "#missing values any from the dataset\n",
    "print(str('Any missing data or NaN in the dataset:'), dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pECIHii2v9U4",
    "outputId": "0edc8041-80e4-4b56-f07f-bf1427cc9d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum and maximum values are 0.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "#data ranges in the dataset - sample\n",
    "print(\"The minimum and maximum values are {}, {}\".format(np.min(dataset.iloc[-2,:].values), np.max(dataset.iloc[-2,:].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCDNFK0uv9U4",
    "outputId": "7ad5528c-43c0-4066-add9-314dba3f59e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10505\n",
       "0.0     4045\n",
       "Name: 187, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for target value count\n",
    "label_dataset = dataset[187].value_counts()\n",
    "label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "oYqqOUpjv9U4",
    "outputId": "29d5e65c-23b2-444b-e9cc-04d88fc35226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization for target label\n",
    "label_dataset.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WEGpVijgv9U4"
   },
   "outputs": [],
   "source": [
    "#splitting dataset to dependent and independent variable\n",
    "X = dataset.iloc[:,:-1].values #independent values / features\n",
    "y = dataset.iloc[:,-1].values #dependent values / target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iGsK-2_tv9U5"
   },
   "outputs": [],
   "source": [
    "#splitting the datasets for training and testing process\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njfzHJIdv9U5",
    "outputId": "56e6006b-c042-464b-dfd5-478675fa53e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train: (10185, 187)\n",
      "size of X_test: (4365, 187)\n",
      "size of y_train: (10185,)\n",
      "size of y_test: (4365,)\n"
     ]
    }
   ],
   "source": [
    "#size for the sets\n",
    "print('size of X_train:', X_train.shape)\n",
    "print('size of X_test:', X_test.shape)\n",
    "print('size of y_train:', y_train.shape)\n",
    "print('size of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cquxOI5xv9U5"
   },
   "source": [
    "                                          ###Deep Learning Algorithms###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hdt0P9AMv9U6"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dropout, MaxPool1D \n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LFVuT2SEv9U6"
   },
   "outputs": [],
   "source": [
    "# Create sequential model \n",
    "feature_extractor = Sequential()\n",
    "\n",
    "#1st block Conv 8 \n",
    "feature_extractor.add(Conv1D(filters=8, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 16 \n",
    "feature_extractor.add(Conv1D(filters=16, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 32\n",
    "feature_extractor.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 64\n",
    "feature_extractor.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 128\n",
    "feature_extractor.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 256\n",
    "feature_extractor.add(Conv1D(filters=256, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#1st block Conv 512\n",
    "feature_extractor.add(Conv1D(filters=512, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\n",
    "feature_extractor.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "\n",
    "#Flatten the output\n",
    "feature_extractor.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xoe-x13Wv9U7"
   },
   "outputs": [],
   "source": [
    "#Add layers for deep learning prediction\n",
    "x = feature_extractor.output  \n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "prediction_layer = Dense(1, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHJvnlRyv9U7",
    "outputId": "d1dfa1ae-a136-456e-f6ac-4322e9f93866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_input (InputLayer)   [(None, 187, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 187, 8)            32        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 94, 8)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 94, 16)            400       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 47, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 47, 32)            1568      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 24, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 24, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 12, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 12, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 6, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 6, 256)            98560     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 3, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 3, 512)            393728    \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 2, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,575,825\n",
      "Trainable params: 1,575,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Make a new model combining both feature extractor and x\n",
    "from keras.models import Model\n",
    "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
    "cnn_model.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(cnn_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_4yL7AAv9U7",
    "outputId": "9ce037c3-916f-4813-9342-9f9b6defbfe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 7s 21ms/step - loss: 0.3717 - accuracy: 0.7215 - val_loss: 0.2905 - val_accuracy: 0.7233\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 6s 20ms/step - loss: 0.1943 - accuracy: 0.7215 - val_loss: 0.1129 - val_accuracy: 0.7233\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 6s 20ms/step - loss: 0.1286 - accuracy: 0.7215 - val_loss: 0.1008 - val_accuracy: 0.7233\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 7s 21ms/step - loss: 0.1004 - accuracy: 0.7215 - val_loss: 0.0899 - val_accuracy: 0.7233\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 6s 20ms/step - loss: 0.0825 - accuracy: 0.7215 - val_loss: 0.0738 - val_accuracy: 0.7233\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 6s 19ms/step - loss: 0.0712 - accuracy: 0.7215 - val_loss: 0.0569 - val_accuracy: 0.7233\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 6s 19ms/step - loss: 0.0684 - accuracy: 0.7215 - val_loss: 0.0631 - val_accuracy: 0.7233\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 6s 18ms/step - loss: 0.0585 - accuracy: 0.7215 - val_loss: 0.0940 - val_accuracy: 0.7233\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 6s 18ms/step - loss: 0.0498 - accuracy: 0.7215 - val_loss: 0.0763 - val_accuracy: 0.7233\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 6s 18ms/step - loss: 0.0379 - accuracy: 0.7215 - val_loss: 0.1158 - val_accuracy: 0.7233\n"
     ]
    }
   ],
   "source": [
    "#Train the CNN model\n",
    "history = cnn_model.fit(X_train, y_train, epochs=10, validation_data = (X_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8K4FwcQtAOcF",
    "outputId": "a49c575d-70d0-4259-a047-a8d93edec1e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087,\n",
       " 0.7214531302452087]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "yFXx2jOLv9U7",
    "outputId": "11066701-59ff-4753-bf2e-ac5222856837"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "lx_JFWj8v9U7",
    "outputId": "4155ec38-a65d-4083-8f83-736bac38626d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "IHlbr01yv9U8"
   },
   "outputs": [],
   "source": [
    "prediction_NN = cnn_model.predict(X_test)\n",
    "prediction_NN = np.argmax(prediction_NN, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyfFgsjov9U8",
    "outputId": "6535c2eb-0a3b-4b7f-eca8-eb4f8b65de7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      1.00      0.43      1208\n",
      "         1.0       0.00      0.00      0.00      3157\n",
      "\n",
      "    accuracy                           0.28      4365\n",
      "   macro avg       0.14      0.50      0.22      4365\n",
      "weighted avg       0.08      0.28      0.12      4365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(y_test, prediction_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXpJrFGLv9U8",
    "outputId": "3fb7fb1c-0ce2-417c-9990-76466a73ab6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9830469644902634\n",
      "2.4492223262786865\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for RF\n",
    "X_for_RF = feature_extractor.predict(X_train) #This is out X input to RF\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "import time \n",
    "t1=time.time()\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "t2=time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_feature)\n",
    "\n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_RF))\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ov_Zo-WF0G4T",
    "outputId": "918b37f7-ecf9-4e2b-a214-3292b16c1973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.98      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.98      0.98      0.98      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPlRNd9Rv9U9",
    "outputId": "7ddff1f3-19ba-40fa-abcc-9d6895537857"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy =  0.9855670103092784\n",
      "3.8425092697143555\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for xgb\n",
    "X_for_xgb = feature_extractor.predict(X_train) #This is out X input to xgb\n",
    "\n",
    "#xgb\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "t3=time.time()\n",
    "# Train the model on training data\n",
    "xgb_model.fit(X_for_xgb, y_train) #For sklearn no one hot encoding\n",
    "t4=time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_xgb = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained RF model. \n",
    "prediction_xgb = xgb_model.predict(X_test_feature_xgb)\n",
    "\n",
    "#Print overall accuracy\n",
    "\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_xgb))\n",
    "print(t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tOwhjiO0MpK",
    "outputId": "b69010e0-8be3-441e-e49d-2a3e77369d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.99      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.99      0.99      0.99      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaaOCi4jv9U-",
    "outputId": "a888a2f1-22e0-4a38-c453-56ab0c5339b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9855670103092784\n",
      "14.951289176940918\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for hgb\n",
    "X_for_hgb = feature_extractor.predict(X_train) #This is out X input to xgb\n",
    "\n",
    "# HistGradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgb_model = HistGradientBoostingClassifier(max_bins=255, max_iter=100)\n",
    "\n",
    "t5=time.time()\n",
    "# Train the model on training data\n",
    "hgb_model.fit(X_for_hgb, y_train) #For sklearn no one hot encoding\n",
    "t6=time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_hgb = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained hgb model. \n",
    "prediction_hgb = hgb_model.predict(X_test_feature_hgb)\n",
    "\n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_hgb))\n",
    "print(t6-t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxTUb5nk0PTy",
    "outputId": "ac4d6008-9354-43ee-cbc7-c545b3b34a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.99      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.99      0.99      0.99      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_hgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ch4xbNErv9U_",
    "outputId": "a17ee60e-b297-4d88-c232-c91c267129a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9844215349369989\n",
      "0.0070040225982666016\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for KNN\n",
    "X_for_knn = feature_extractor.predict(X_train) #This is out X input to knn\n",
    "\n",
    "#KNearest Neighbour\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "t7 = time.time()\n",
    "# Train the model on training data\n",
    "knn.fit(X_for_knn, y_train) #For sklearn no one hot encoding\n",
    "t8 = time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_knn = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained hgb model. \n",
    "prediction_knn = knn.predict(X_test_feature_knn)\n",
    "\n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_knn))\n",
    "print(t8-t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NI3y3e9Q0RkZ",
    "outputId": "2960a89f-658f-4b10-b858-889897f47b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.98      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.98      0.98      0.98      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdUv3gGIv9U_",
    "outputId": "df285d87-1704-46c3-9b21-e7ca6e00246d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.986483390607102\n",
      "5.4129016399383545\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for SVM Linear\n",
    "X_for_svml = feature_extractor.predict(X_train) #This is out X input to knn\n",
    "\n",
    "#SVM_linear\n",
    "from sklearn.svm import SVC\n",
    "svml = SVC(kernel = 'linear', C=8.5, random_state =42)\n",
    "svml.fit(X_train,y_train)\n",
    "\n",
    "t9 = time.time()\n",
    "# Train the model on training data\n",
    "svml.fit(X_for_svml, y_train) #For sklearn no one hot encoding\n",
    "t10 = time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_svml = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained hgb model. \n",
    "prediction_svml = svml.predict(X_test_feature_svml)\n",
    "\n",
    "#Print overall accuracy\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_svml))\n",
    "print(t10-t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qNXWl2x0Tny",
    "outputId": "3143c196-3fce-4d63-c077-0d042a0bc4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.99      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.99      0.99      0.99      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_svml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sxj4IVYBv9U_",
    "outputId": "67e0515c-75d9-4e68-aa30-624eb9af4073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9825887743413516\n",
      "6.11452841758728\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for SVM RBF\n",
    "X_for_svmr = feature_extractor.predict(X_train) #This is out X input to knn\n",
    "\n",
    "#SVM_rbf\n",
    "from sklearn.svm import SVC\n",
    "svmr = SVC(kernel = 'rbf', C= 4.5, gamma = 0.1, random_state = 42)\n",
    "svmr.fit(X_train,y_train)\n",
    "\n",
    "import time\n",
    "t11 = time.time()\n",
    "# Train the model on training data\n",
    "svmr.fit(X_for_svmr, y_train) #For sklearn no one hot encoding\n",
    "t12 = time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_svmr = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained hgb model. \n",
    "prediction_svmr = svmr.predict(X_test_feature_svmr)\n",
    "\n",
    "#Print overall accuracy\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_svmr))\n",
    "print(t12-t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmeJqx-Z0W_a",
    "outputId": "135e334e-928b-4882-b466-aca3ed55b581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      1208\n",
      "         1.0       0.99      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.98      4365\n",
      "   macro avg       0.98      0.98      0.98      4365\n",
      "weighted avg       0.98      0.98      0.98      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_svmr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7o9WIgcHv9VA",
    "outputId": "bf2ba9ef-e644-48db-f8b9-771246e42432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9814432989690721\n",
      "7.483180046081543\n"
     ]
    }
   ],
   "source": [
    "#Now, let us use features from convolutional network for svm polynomial\n",
    "X_for_svmp = feature_extractor.predict(X_train) #This is out X input to knn\n",
    "\n",
    "#SVM_rbf\n",
    "from sklearn.svm import SVC\n",
    "svmp = SVC(kernel = 'poly', C=4.5, degree = 3, random_state = 42)\n",
    "svmp.fit(X_train,y_train)\n",
    "\n",
    "import time\n",
    "t13 = time.time()\n",
    "# Train the model on training data\n",
    "svmp.fit(X_for_svmp, y_train) #For sklearn no one hot encoding\n",
    "t14 = time.time()\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature_svmp = feature_extractor.predict(X_test)\n",
    "\n",
    "#Now predict using the trained hgb model. \n",
    "prediction_svmp = svmp.predict(X_test_feature_svmp)\n",
    "\n",
    "#Print overall accuracy\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_svmp))\n",
    "print(t14-t13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBZDZbgk0Zpa",
    "outputId": "ac481b36-6561-486a-8149-47307c27f389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97      1208\n",
      "         1.0       0.98      0.99      0.99      3157\n",
      "\n",
      "    accuracy                           0.98      4365\n",
      "   macro avg       0.98      0.97      0.98      4365\n",
      "weighted avg       0.98      0.98      0.98      4365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_svmp))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ptdb_dataset_cnn_ml_30_12_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
